{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0pMyzEWE6RXS9aVhD+bd3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23b287ba28ed4216b5b0c302f211d488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc0a732f4b4645f5a8a91fd058c1f722",
              "IPY_MODEL_c89dd796a36e4dbbae996a5a1d980ec2",
              "IPY_MODEL_89d7a981dfc74d22925f581c549824b0"
            ],
            "layout": "IPY_MODEL_6a748cd8300b4a989bb528556b13104c"
          }
        },
        "dc0a732f4b4645f5a8a91fd058c1f722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_505896d30f0f41de92085cd6e68b5444",
            "placeholder": "​",
            "style": "IPY_MODEL_69a2c3ae4f5d4425a94f6f563a61710a",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "c89dd796a36e4dbbae996a5a1d980ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7467d830b2746718425a40207dfd338",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44498017dd3243be80ccc11967b224ce",
            "value": 6
          }
        },
        "89d7a981dfc74d22925f581c549824b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c32a16a208401ab18efa6e60041e30",
            "placeholder": "​",
            "style": "IPY_MODEL_8662c96904234e27ad101a109229df1c",
            "value": " 6/6 [00:18&lt;00:00,  4.01s/it]"
          }
        },
        "6a748cd8300b4a989bb528556b13104c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505896d30f0f41de92085cd6e68b5444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a2c3ae4f5d4425a94f6f563a61710a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7467d830b2746718425a40207dfd338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44498017dd3243be80ccc11967b224ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83c32a16a208401ab18efa6e60041e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8662c96904234e27ad101a109229df1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-jk/painting-lora-finetune/blob/main/paintings_lora_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J8ajJ7_uIKOr",
        "outputId": "1dfc979d-cc6c-48a8-aabe-34909c1101d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-07 22:43:52--  https://raw.githubusercontent.com/alex-jk/painting-lora-finetune/main/data/paintings.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7164316 (6.8M) [application/zip]\n",
            "Saving to: ‘paintings.zip’\n",
            "\n",
            "paintings.zip       100%[===================>]   6.83M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-04-07 22:43:52 (107 MB/s) - ‘paintings.zip’ saved [7164316/7164316]\n",
            "\n",
            "Archive:  paintings.zip\n",
            "   creating: paintings/paintings/\n",
            "  inflating: paintings/paintings/17030-islands-on-kabenung-40x60-brigitte-granton_orig.jpeg  \n",
            "  inflating: paintings/paintings/23060-Setting-in-a-Grand-Way-Grand-Lake-30X60_-3240.jpeg  \n",
            "  inflating: paintings/paintings/24055-Sunswept-Opeongo-40x48_-oil-Algonquin-G-539x443.jpeg  \n",
            "  inflating: paintings/paintings/30yl2012ivanhoethechute600.jpg  \n",
            "  inflating: paintings/paintings/4bc1b40a29aa1ea4f1bb86bb1177a578.jpg  \n",
            "  inflating: paintings/paintings/bierstadt_albert_lake_tahoe_california_1863.jpg  \n",
            "  inflating: paintings/paintings/converted_image.jpg  \n",
            "  inflating: paintings/paintings/converted_image_2.jpg  \n",
            "  inflating: paintings/paintings/converted_image_3.jpg  \n",
            "  inflating: paintings/paintings/DSC_1060.JPG  \n",
            "  inflating: paintings/paintings/Flowing-800x588.jpg  \n",
            "  inflating: paintings/paintings/ga0445-garth-armstrong-36x48-oil-on-canvas-uf-1030x773.jpg  \n",
            "  inflating: paintings/paintings/geG4QZcDv2.jpg  \n",
            "  inflating: paintings/paintings/GXSgpwOWoAMS35k.jpg  \n",
            "  inflating: paintings/paintings/H0077-L67207199.jpg  \n",
            "  inflating: paintings/paintings/Ivan-Shishkin-Mast-Tree-Grove-1898.jpg  \n",
            "  inflating: paintings/paintings/john-barrie-rennie-boyd-bay-muskoka-2.jpg  \n",
            "  inflating: paintings/paintings/k.-rempel-rushing-river.jpeg  \n",
            "  inflating: paintings/paintings/Little-Waterfall-Algonquin-2422-x-1822-Soft-Pastel.jpg  \n",
            "  inflating: paintings/paintings/maribelli_shallows_36x60.jpg  \n",
            "  inflating: paintings/paintings/Melissa-Jean-Strawberry-island.jpg.jpeg  \n",
            "  inflating: paintings/paintings/Muskoka++2022+web+size.jpg  \n",
            "  inflating: paintings/paintings/swiftwater-nancy-jolley.jpg  \n",
            "  inflating: paintings/paintings/the-evening-hour-jake-vandenbrink.jpg  \n",
            "  inflating: paintings/paintings/unnamed.jpg  \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/alex-jk/painting-lora-finetune/main/data/paintings.zip -O paintings.zip\n",
        "!unzip -o paintings.zip -d paintings/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers"
      ],
      "metadata": {
        "id": "-MFiOoblY8C7",
        "outputId": "b35178c7-8dec-48ed-d31d-e5be1274dbcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from xformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->xformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->xformers) (3.0.2)\n",
            "Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, xformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xformers-0.0.29.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y diffusers\n",
        "!pip install git+https://github.com/huggingface/diffusers.git"
      ],
      "metadata": {
        "id": "xd84aCQ6b20G",
        "outputId": "4754983d-7faa-45c1-873f-dba8d0cadd5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: diffusers 0.32.2\n",
            "Uninstalling diffusers-0.32.2:\n",
            "  Successfully uninstalled diffusers-0.32.2\n",
            "Collecting git+https://github.com/huggingface/diffusers.git\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-xoo5zgip\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-xoo5zgip\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit 506f39af3a7b533209cc96f1732fff347070bdbd\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (0.30.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.0.dev0) (11.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers==0.33.0.dev0) (4.13.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers==0.33.0.dev0) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.33.0.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.33.0.dev0-py3-none-any.whl size=3544299 sha256=3603ef0ecdcb275c0792cd5ced8c31e14abc3bd5bbc7d2d6c004793106dff9fe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yumqx2rg/wheels/d2/5c/5f/16639722ea17ecb73ab461b81718584bac08af2801619786b9\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.33.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import diffusers\n",
        "print(diffusers.__version__)\n",
        "\n",
        "from diffusers import StableDiffusionPipeline, UNet2DConditionModel\n",
        "import torch\n",
        "\n",
        "from peft import LoraConfig # TaskType is no longer needed here\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms # Import torchvision for image transforms\n",
        "from torch.utils.data import Dataset, DataLoader # Import Dataset and DataLoader\n",
        "from PIL import Image # Import PIL for image loading\n",
        "import os # Import os for path manipulation\n",
        "import glob\n",
        "import subprocess # Better way to run shell commands"
      ],
      "metadata": {
        "id": "U1CHBIRbJPoY",
        "outputId": "1e401f8f-534b-4e1b-9641-705e573cfe98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.33.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None\n",
        ").to(\"cuda\")"
      ],
      "metadata": {
        "id": "uZyzErOcPcTE",
        "outputId": "0298592a-28e4-420b-aadf-79014ef02dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "23b287ba28ed4216b5b0c302f211d488",
            "dc0a732f4b4645f5a8a91fd058c1f722",
            "c89dd796a36e4dbbae996a5a1d980ec2",
            "89d7a981dfc74d22925f581c549824b0",
            "6a748cd8300b4a989bb528556b13104c",
            "505896d30f0f41de92085cd6e68b5444",
            "69a2c3ae4f5d4425a94f6f563a61710a",
            "e7467d830b2746718425a40207dfd338",
            "44498017dd3243be80ccc11967b224ce",
            "83c32a16a208401ab18efa6e60041e30",
            "8662c96904234e27ad101a109229df1c"
          ]
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23b287ba28ed4216b5b0c302f211d488"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable LoRA training in the U-Net\n",
        "pipe.unet.enable_gradient_checkpointing()\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ],
      "metadata": {
        "id": "eQD4oAihPjAd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a reference to the UNet model\n",
        "unet = pipe.unet\n",
        "print(\"UNet reference obtained.\")\n",
        "# 2. Define the LoRA configuration object\n",
        "#    Omitting task_type as it's not required for unet.add_adapter()\n",
        "#    and the previous enum value was incorrect.\n",
        "lora_config = LoraConfig(\n",
        "    r=4,\n",
        "    lora_alpha=4,\n",
        "    target_modules=[\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    # task_type=... # REMOVED - Not needed here and caused AttributeError\n",
        ")\n",
        "\n",
        "print(\"LoRA Config defined (without task_type).\")"
      ],
      "metadata": {
        "id": "boixaRjuRPOg",
        "outputId": "b6957734-1768-4f7d-849e-019a92fabc9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNet reference obtained.\n",
            "LoRA Config defined (without task_type).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Add the LoRA adapter to the UNet model using the defined config\n",
        "#    The 'adapter_name' is optional but good practice if you plan\n",
        "#    to manage multiple adapters later.\n",
        "adapter_name = \"my_style_lora\" # You can choose any descriptive name\n",
        "unet.add_adapter(lora_config, adapter_name=adapter_name)\n",
        "\n",
        "print(f\"LoRA adapter '{adapter_name}' added to the UNet.\")\n",
        "\n",
        "# Optional but recommended: Verify trainable parameters\n",
        "# This helps confirm that only the LoRA weights are set to be trained.\n",
        "trainable_params = 0\n",
        "all_param = 0\n",
        "for name, param in unet.named_parameters():\n",
        "    all_param += param.numel()\n",
        "    if param.requires_grad:\n",
        "        # Print trainable parameter names (optional, for debugging)\n",
        "        # print(f\"Trainable: {name}\")\n",
        "        trainable_params += param.numel()\n",
        "\n",
        "print(\n",
        "    f\"\\nTotal UNet params: {all_param:,}\\n\"\n",
        "    f\"Trainable params (LoRA): {trainable_params:,}\\n\"\n",
        "    f\"Trainable %: {100 * trainable_params / all_param:.4f}%\"\n",
        ")"
      ],
      "metadata": {
        "id": "nmDzG9ddd3q2",
        "outputId": "cea3fc01-407d-425f-c8b3-483a47ea0e0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA adapter 'my_style_lora' added to the UNet.\n",
            "\n",
            "Total UNet params: 860,318,148\n",
            "Trainable params (LoRA): 797,184\n",
            "Trainable %: 0.0927%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Set up the Optimizer\n",
        "#    Filter the UNet's parameters to get only those that require gradients (the LoRA parameters).\n",
        "lora_params_to_optimize = [p for p in unet.parameters() if p.requires_grad]\n",
        "print(f\"Number of parameter groups to optimize: {len(lora_params_to_optimize)}\")\n",
        "\n",
        "# Define common hyperparameters for the optimizer\n",
        "learning_rate = 1e-4 # A common starting LR for LoRA training\n",
        "adam_beta1 = 0.9\n",
        "adam_beta2 = 0.999\n",
        "adam_weight_decay = 1e-2\n",
        "adam_epsilon = 1e-08\n",
        "\n",
        "# Create the AdamW optimizer, passing only the LoRA parameters\n",
        "optimizer = optim.AdamW(\n",
        "    lora_params_to_optimize,\n",
        "    lr=learning_rate,\n",
        "    betas=(adam_beta1, adam_beta2),\n",
        "    weight_decay=adam_weight_decay,\n",
        "    eps=adam_epsilon,\n",
        ")\n",
        "\n",
        "print(f\"Optimizer AdamW created with learning rate {learning_rate}.\")"
      ],
      "metadata": {
        "id": "HpDwjTA9eEcj",
        "outputId": "b7548dc9-2bf6-4b22-a509-88026e56e5ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameter groups to optimize: 256\n",
            "Optimizer AdamW created with learning rate 0.0001.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get references to VAE, Text Encoder, Tokenizer, and Scheduler from the pipeline\n",
        "vae = pipe.vae\n",
        "text_encoder = pipe.text_encoder\n",
        "tokenizer = pipe.tokenizer\n",
        "scheduler = pipe.scheduler # The noise scheduler\n",
        "\n",
        "print(\"VAE, Text Encoder, Tokenizer, and Scheduler extracted from pipeline.\")\n",
        "\n",
        "# Freeze VAE and Text Encoder parameters\n",
        "# These models should not be trained during LoRA fine-tuning of the UNet\n",
        "vae.requires_grad_(False)\n",
        "text_encoder.requires_grad_(False)\n",
        "\n",
        "print(\"VAE and Text Encoder parameters frozen (requires_grad=False).\")\n",
        "\n",
        "# Optional: Move VAE and Text Encoder to appropriate dtype and device if not already done\n",
        "# (The pipe.to(\"cuda\") should have handled this, but explicit check/move can be useful)\n",
        "# vae.to(unet.device, dtype=torch.float16) # Match UNet's device and potentially dtype\n",
        "# text_encoder.to(unet.device) # Text encoder usually stays float32\n",
        "\n",
        "# Verify UNet is still in training mode (add_adapter should preserve this)\n",
        "if not unet.training:\n",
        "    unet.train()\n",
        "    print(\"Set UNet back to training mode.\")\n",
        "else:\n",
        "    print(\"UNet is already in training mode.\")"
      ],
      "metadata": {
        "id": "sK68dX5qE1Lz",
        "outputId": "a479b271-be9c-4427-87d1-883b2a1ede03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE, Text Encoder, Tokenizer, and Scheduler extracted from pipeline.\n",
            "VAE and Text Encoder parameters frozen (requires_grad=False).\n",
            "UNet is already in training mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Code just for checking the directory ---\n",
        "\n",
        "# Define the directory where files were supposed to be unzipped\n",
        "base_data_dir = \"paintings\"\n",
        "possible_subdir = os.path.join(base_data_dir, \"paintings\") # Common pattern if zip contained a 'paintings' folder\n",
        "\n",
        "print(f\"--- Checking contents of '{base_data_dir}' ---\")\n",
        "\n",
        "# Check if the base directory exists\n",
        "if not os.path.isdir(base_data_dir):\n",
        "    print(f\"Error: Directory '{base_data_dir}' does not exist.\")\n",
        "else:\n",
        "    # List immediate contents\n",
        "    print(f\"\\nDirect contents of '{base_data_dir}':\")\n",
        "    try:\n",
        "        for item in os.listdir(base_data_dir):\n",
        "            item_path = os.path.join(base_data_dir, item)\n",
        "            item_type = \"DIR\" if os.path.isdir(item_path) else \"FILE\"\n",
        "            print(f\"- {item} ({item_type})\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error listing contents: {e}\")\n",
        "\n",
        "\n",
        "    # Look for image files directly inside base_data_dir\n",
        "    image_extensions = ('*.png', '*.jpg', '*.jpeg', '*.webp')\n",
        "    images_in_base = []\n",
        "    for ext in image_extensions:\n",
        "        images_in_base.extend(glob.glob(os.path.join(base_data_dir, ext)))\n",
        "\n",
        "    if images_in_base:\n",
        "        print(f\"\\nFound {len(images_in_base)} image(s) directly in '{base_data_dir}'. Example: {os.path.basename(images_in_base[0])}\")\n",
        "    else:\n",
        "        print(f\"\\nNo image files found directly in '{base_data_dir}'.\")\n",
        "\n",
        "    # Check if the common subdirectory exists and look for images there\n",
        "    if os.path.isdir(possible_subdir):\n",
        "        print(f\"\\nChecking common subdirectory '{possible_subdir}'...\")\n",
        "        images_in_subdir = []\n",
        "        for ext in image_extensions:\n",
        "            images_in_subdir.extend(glob.glob(os.path.join(possible_subdir, ext)))\n",
        "\n",
        "        if images_in_subdir:\n",
        "            print(f\"Found {len(images_in_subdir)} image(s) in subdirectory '{possible_subdir}'. Example: {os.path.basename(images_in_subdir[0])}\")\n",
        "        else:\n",
        "            print(f\"No image files found in subdirectory '{possible_subdir}'.\")\n",
        "    else:\n",
        "         print(f\"\\nCommon subdirectory '{possible_subdir}' does not exist.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- End Check ---\")"
      ],
      "metadata": {
        "id": "RWVdTGUgH8aO",
        "outputId": "3b89093b-fbb5-4654-89f9-7502277ed367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Checking contents of 'paintings' ---\n",
            "\n",
            "Direct contents of 'paintings':\n",
            "- paintings (DIR)\n",
            "\n",
            "No image files found directly in 'paintings'.\n",
            "\n",
            "Checking common subdirectory 'paintings/paintings'...\n",
            "Found 24 image(s) in subdirectory 'paintings/paintings'. Example: the-evening-hour-jake-vandenbrink.jpg\n",
            "\n",
            "--- End Check ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download, Extract Data, and Prepare Dataset/DataLoader\n",
        "\n",
        "# Define data source and target directory\n",
        "data_url = \"https://raw.githubusercontent.com/alex-jk/painting-lora-finetune/main/data/paintings.zip\"\n",
        "zip_file = \"paintings.zip\"\n",
        "data_dir = \"paintings\" # Directory where data will be unzipped\n",
        "\n",
        "# Create target directory if it doesn't exist\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Download the data if zip file doesn't exist\n",
        "if not os.path.exists(zip_file):\n",
        "    print(f\"Downloading data from {data_url}...\")\n",
        "    try:\n",
        "        # Using subprocess for better error handling than '!' in some environments\n",
        "        subprocess.run([\"wget\", data_url, \"-O\", zip_file], check=True)\n",
        "        print(\"Download complete.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error downloading file: {e}\")\n",
        "        # Handle error appropriately, maybe raise exception\n",
        "        raise SystemExit(f\"Failed to download data: {e}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: 'wget' command not found. Please ensure wget is installed.\")\n",
        "        raise SystemExit(\"wget not found.\")\n",
        "else:\n",
        "    print(f\"Zip file '{zip_file}' already exists. Skipping download.\")\n",
        "\n",
        "# Unzip the data\n",
        "print(f\"Unzipping {zip_file} into {data_dir}...\")\n",
        "try:\n",
        "    # Use -o to overwrite existing files without prompting\n",
        "    subprocess.run([\"unzip\", \"-o\", zip_file, \"-d\", data_dir], check=True, capture_output=True)\n",
        "    print(\"Unzipping complete.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error unzipping file: {e}\")\n",
        "    print(f\"Stderr: {e.stderr.decode()}\")\n",
        "    raise SystemExit(f\"Failed to unzip data: {e}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'unzip' command not found. Please ensure unzip is installed.\")\n",
        "    raise SystemExit(\"unzip not found.\")"
      ],
      "metadata": {
        "id": "9tJNfK6wG-Bg",
        "outputId": "44acf337-fae9-4bd1-8458-21b40235e30e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zip file 'paintings.zip' already exists. Skipping download.\n",
            "Unzipping paintings.zip into paintings...\n",
            "Unzipping complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Hyperparameters for data preparation\n",
        "image_resolution = 512 # Match the resolution SD v1.5 was trained on\n",
        "batch_size = 4       # Adjust based on your GPU memory (start small)\n",
        "\n",
        "# Define Image Transformations\n",
        "preprocess = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(image_resolution, interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "        transforms.CenterCrop(image_resolution),\n",
        "        transforms.ToTensor(), # Convert image to tensor [0, 1]\n",
        "        transforms.Normalize([0.5], [0.5]), # Normalize to [-1, 1]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define Custom Dataset pointing to the 'paintings' directory\n",
        "class PaintingStyleDataset(Dataset):\n",
        "    def __init__(self, instance_data_root, tokenizer, size=512):\n",
        "        self.instance_data_root = instance_data_root\n",
        "        self.tokenizer = tokenizer # Keep tokenizer reference if needed later\n",
        "        self.size = size\n",
        "\n",
        "        self.instance_images_path = []\n",
        "        valid_extensions = ('.png', '.jpg', '.jpeg', '.webp')\n",
        "        if not os.path.isdir(instance_data_root):\n",
        "             raise ValueError(f\"Dataset directory '{instance_data_root}' not found after unzipping.\")\n",
        "\n",
        "        for filename in os.listdir(instance_data_root):\n",
        "            if filename.lower().endswith(valid_extensions):\n",
        "                self.instance_images_path.append(os.path.join(instance_data_root, filename))\n",
        "\n",
        "        self.num_instance_images = len(self.instance_images_path)\n",
        "        self._length = self.num_instance_images\n",
        "        self.image_transforms = preprocess\n",
        "\n",
        "        if self.num_instance_images == 0:\n",
        "             print(f\"Warning: No valid image files found in {instance_data_root}. Check the directory structure and file extensions.\")\n",
        "        else:\n",
        "            print(f\"Dataset initialized: Found {self.num_instance_images} images in {instance_data_root}\")\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = {}\n",
        "        if index >= self.num_instance_images: # Should not happen with DataLoader but safe check\n",
        "             raise IndexError(\"Index out of bounds\")\n",
        "\n",
        "        instance_image_path = self.instance_images_path[index]\n",
        "        try:\n",
        "            instance_image = Image.open(instance_image_path)\n",
        "            if not instance_image.mode == \"RGB\":\n",
        "                instance_image = instance_image.convert(\"RGB\")\n",
        "            example[\"instance_images\"] = self.image_transforms(instance_image)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load image {instance_image_path}. Error: {e}. Skipping index {index}.\")\n",
        "            # Return None to indicate failure, handled in collate_fn\n",
        "            return None\n",
        "\n",
        "        # Define the text prompt for training.\n",
        "        # Since we're training a style, use a consistent prompt with a trigger word.\n",
        "        # <<< IMPORTANT: Replace 'sks painting style' with your desired trigger phrase >>>\n",
        "        instance_prompt = \"a painting in sks painting style\"\n",
        "        example[\"instance_prompt\"] = instance_prompt # Store the raw text prompt\n",
        "\n",
        "        return example\n",
        "\n",
        "# Define the Collate Function (handles potential None values from failed image loads)\n",
        "def simple_collate_fn(examples):\n",
        "    # Filter out None entries (failed image loads)\n",
        "    valid_examples = [ex for ex in examples if ex is not None]\n",
        "    if not valid_examples: # Handle case where entire batch failed\n",
        "        return None # Or however your training loop handles empty batches\n",
        "\n",
        "    # Stack images\n",
        "    pixel_values = torch.stack([example[\"instance_images\"] for example in valid_examples])\n",
        "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
        "\n",
        "    # Collect prompts\n",
        "    prompts = [example[\"instance_prompt\"] for example in valid_examples]\n",
        "\n",
        "    return {\"pixel_values\": pixel_values, \"prompts\": prompts}"
      ],
      "metadata": {
        "id": "nMI_1aNba4Ip",
        "outputId": "33661552-d07b-45c6-8ccd-72178e8f81a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transforms' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-469e369da727>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define Image Transformations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m preprocess = transforms.Compose(\n\u001b[0m\u001b[1;32m      7\u001b[0m     [\n\u001b[1;32m      8\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_resolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpolationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual_image_dir = \"paintings/paintings\"\n",
        "\n",
        "# Instantiate the Dataset using the 'data_dir' ('paintings')\n",
        "train_dataset = PaintingStyleDataset(\n",
        "    instance_data_root=data_dir,\n",
        "    tokenizer=tokenizer,\n",
        "    size=image_resolution\n",
        ")\n",
        "\n",
        "# Create the DataLoader only if the dataset has images\n",
        "if len(train_dataset) > 0:\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        shuffle=True,\n",
        "        collate_fn=simple_collate_fn,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2 # Adjust based on your system\n",
        "    )\n",
        "    print(f\"DataLoader created with batch size {batch_size}.\")\n",
        "\n",
        "    # Optional: Test the dataloader\n",
        "    # try:\n",
        "    #     first_batch = next(iter(train_dataloader))\n",
        "    #     if first_batch:\n",
        "    #         print(\"First batch keys:\", first_batch.keys())\n",
        "    #         print(\"Image batch shape:\", first_batch['pixel_values'].shape)\n",
        "    #         print(f\"Number of prompts in batch: {len(first_batch['prompts'])}\")\n",
        "    #     else:\n",
        "    #         print(\"First batch was empty (all image loads failed?).\")\n",
        "    # except StopIteration:\n",
        "    #     print(\"DataLoader is empty (dataset likely has zero length).\")\n",
        "\n",
        "else:\n",
        "    print(\"DataLoader not created because the dataset is empty.\")\n",
        "    train_dataloader = None # Ensure it's None if not created"
      ],
      "metadata": {
        "id": "EdKfWluAHloP",
        "outputId": "3f156d14-50f9-4a90-b918-6c402995d8f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No valid image files found in paintings. Check the directory structure and file extensions.\n",
            "DataLoader not created because the dataset is empty.\n"
          ]
        }
      ]
    }
  ]
}